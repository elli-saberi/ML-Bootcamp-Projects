{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "train = pd.read_csv('../data/train.csv',na_values='unknown')\n",
    "test = pd.read_csv('../data/test.csv',na_values='unknown')\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['marital'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = ['default','housing','loan']\n",
    "ordinal_cols = {\n",
    "    'education':{\"illiterate\":0 , \"basic.4y\":1 ,\"basic.6y\":2 , \"basic.9y\":3 , \"high.school\":4 ,\n",
    "                 \"professional.course\":5 , \"university.degree\":6},\n",
    "    'job': {'student':0 , 'unemployed':1 , 'housemaid':2 , 'services':3 , 'blue-collar':4 ,\n",
    "            'technician':5 , 'self-employed':6 , 'entrepreneur':7,'admin.':8 , 'management':9 , 'retired':10},\n",
    "    'marital':{'single':0 , 'married':1 , 'divorced':2}\n",
    "}\n",
    "yesNoMapping = {'yes':1,'no':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_ordinal_cols = {col:{v:k for k,v in mapping.items()} for col,mapping in ordinal_cols.items()}\n",
    "inverse_yesNo = {v:k for k,v in yesNoMapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_view(df):\n",
    "    df_num = df.copy()\n",
    "    for col in binary_cols:\n",
    "        df_num[col] = df_num[col].map(yesNoMapping)\n",
    "    for col,mapping in ordinal_cols.items():\n",
    "        df_num[col] = df_num[col].map(mapping)\n",
    "    return df_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "target_features = {\n",
    "    \"job\":[\"age\" , \"education\" , \"marital\" , \"default\" , \"housing\" , \"loan\" , \"campaign\"],\n",
    "    \"marital\":[\"age\" , \"education\" , \"job\" , \"housing\" , \"loan\" , \"campaign\"],\n",
    "    \"education\":[\"age\" , \"job\" , \"marital\" , \"default\" , \"housing\" , \"loan\" , \"campaign\"]\n",
    "}\n",
    "cols = [\"job\" , \"age\" , \"education\" , \"marital\" , \"default\" , \"housing\" , \"loan\" , \"campaign\"]\n",
    "\n",
    "for target_col, feature_cols in target_features.items():\n",
    "    \n",
    "    train_notna_num = numeric_view(train[cols].dropna(subset=[target_col]))\n",
    "    train_missing_num = numeric_view(train[train[target_col].isna()])\n",
    "    test_missing_num = numeric_view(test[test[target_col].isna()])\n",
    "\n",
    "    model = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "    model.fit(train_notna_num[feature_cols], train_notna_num[target_col])\n",
    "    \n",
    "    pred_train = model.predict(train_missing_num[feature_cols])\n",
    "    train.loc[train[target_col].isna(), target_col] = [inverse_ordinal_cols[target_col][p] for p in pred_train]\n",
    "    \n",
    "    pred_test = model.predict(test_missing_num[feature_cols])\n",
    "    test.loc[test[target_col].isna(), target_col] = [inverse_ordinal_cols[target_col][p] for p in pred_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train.columns[train.isna().sum()>0])\n",
    "# print(test.columns[test.isna().sum()>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"default\", \"housing\", \"loan\"]:\n",
    "    modeValue = train[col].mode()[0]\n",
    "    train[col] = train[col].fillna(modeValue)\n",
    "    test[col] = test[col].fillna(modeValue)\n",
    "# print(train.columns[train.isna().sum()>0])\n",
    "# print(test.columns[test.isna().sum()>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['loan'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['job'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for col in train.columns[(train.isna().sum()>0)]:\n",
    "#     modeValue = train[col].mode()[0]\n",
    "#     train[col] = train[col].fillna(modeValue)\n",
    "#     test[col] = test[col].fillna(modeValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Handle categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_cols = ['default','housing','loan']\n",
    "# nominal_cols = ['job','marital','contact']\n",
    "\n",
    "# ordinal_cols = {\n",
    "#     'education':{\"illiterate\":0 , \"basic.4y\":1 ,\"basic.6y\":2 , \"basic.9y\":3 , \"high.school\":4 , \"professional.course\":5 , \"university.degree\":6},\n",
    "#     'month':{\"jan\":0 , \"feb\":1 , \"mar\":2 , \"apr\":3 , \"may\":4 , \"jun\":5 , \"jul\":6 , \"aug\":7 , \"sep\":8 , \"oct\":9 , \"nov\":10 , \"dec\":11},\n",
    "#     'day_of_week':{\"mon\":0 , \"tue\":1 , \"wed\":2 , \"thu\":3 , \"fri\":4 , \"sat\":5 , \"sun\":6},\n",
    "#     'poutcome':{\"failure\":-1 , \"nonexistent\":0 , \"success\":1}\n",
    "# }\n",
    "\n",
    "# yesNoMapping = {'yes':1,'no':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = ['default','housing','loan']\n",
    "nominal_cols = ['marital','contact']\n",
    "\n",
    "ordinal_cols = {\n",
    "    'education':{\"illiterate\":0 , \"basic.4y\":1 ,\"basic.6y\":2 , \"basic.9y\":3 , \"high.school\":4 , \"professional.course\":5 , \"university.degree\":6},\n",
    "    'month':{\"jan\":0 , \"feb\":1 , \"mar\":2 , \"apr\":3 , \"may\":4 , \"jun\":5 , \"jul\":6 , \"aug\":7 , \"sep\":8 , \"oct\":9 , \"nov\":10 , \"dec\":11},\n",
    "    'day_of_week':{\"mon\":0 , \"tue\":1 , \"wed\":2 , \"thu\":3 , \"fri\":4 , \"sat\":5 , \"sun\":6},\n",
    "    'poutcome':{\"failure\":-1 , \"nonexistent\":0 , \"success\":1},\n",
    "    'job': {'student':0 , 'unemployed':1 , 'housemaid':2 , 'services':3 , 'blue-collar':4 ,\n",
    "            'technician':5 , 'self-employed':6 , 'entrepreneur':7,'retired':8 , 'admin.':9 , 'management':10}\n",
    "}\n",
    "\n",
    "yesNoMapping = {'yes':1,'no':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.abs((train.groupby('education')['y'].mean()-0.5)).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = np.abs((train.groupby('education')['y'].mean()-0.5)).sort_values()\n",
    "# {idx:i for i,idx in enumerate(temp.index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def findMapping(col):\n",
    "#     temp = np.abs((train.groupby(col)['y'].mean()-0.5)).sort_values()\n",
    "#     return {idx:i for i,idx in enumerate(temp.index)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_cols = ['default','housing','loan']\n",
    "# nominal_cols = ['marital','contact']\n",
    "\n",
    "\n",
    "# ordinal_cols = {col:findMapping(col) for col in ['education','month','day_of_week','job']}\n",
    "\n",
    "# yesNoMapping = {'yes':1,'no':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in binary_cols:\n",
    "    train[col] = train[col].map(yesNoMapping)\n",
    "    test[col] = test[col].map(yesNoMapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col,mapping in ordinal_cols.items():\n",
    "    train[col] = train[col].map(mapping)\n",
    "    test[col] = test[col].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['poutcome'] = train['poutcome'].map({\"failure\":-1 , \"nonexistent\":0 , \"success\":1})\n",
    "# test['poutcome'] = test['poutcome'].map({\"failure\":-1 , \"nonexistent\":0 , \"success\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[ordinal_cols.keys()].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False,drop='first')\n",
    "encoder.fit(train[nominal_cols])\n",
    "\n",
    "train_encoded = encoder.transform(train[nominal_cols])\n",
    "test_encoded = encoder.transform(test[nominal_cols])\n",
    "\n",
    "encoded_cols = encoder.get_feature_names_out(nominal_cols)\n",
    "\n",
    "train_encoded = pd.DataFrame(train_encoded, columns=encoded_cols, index=train.index)\n",
    "test_encoded = pd.DataFrame(test_encoded, columns=encoded_cols, index=test.index)\n",
    "\n",
    "train = train.drop(nominal_cols, axis=1).join(train_encoded)\n",
    "test = test.drop(nominal_cols, axis=1).join(test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train.pdays==999).sum()/len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (test.pdays==999).sum()/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['call'] = train.pdays==999\n",
    "test['call'] = test.pdays==999\n",
    "# train['call'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['duration','pdays'],axis=1)\n",
    "test = test.drop(['duration','pdays'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.drop(['pdays'],axis=1)\n",
    "# test = test.drop(['pdays'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.abs(train.corr()['y']).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ((np.abs(train.groupby('age')['y'].mean()-0.5)*10)//1).sort_values()\n",
    "# temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['age_group'] = train.age.map(temp)\n",
    "test['age_group'] = test.age.map(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.abs((train.groupby('age_group')['y'].mean()-.5)).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.hist(train[train.y==0].age,bins=80,alpha=.8,label='y = 0')\n",
    "# plt.hist(train[train.y==1].age,bins=80,label='y = 1')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.abs(train.corr()['y'])[['age','age_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop('age',axis=1)\n",
    "test = test.drop('age',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['call_frequency'] =train['campaign'] / (train['previous']+1)\n",
    "test['call_frequency'] = test['campaign'] / (test['previous']+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['prev_success']  = ((train['previous']>0) & (train['poutcome']==1))\n",
    "test['prev_success']  = ((test['previous']>0) & (test['poutcome']==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['high_proirity'] = (train['poutcome']==1) & (train['campaign']>1)\n",
    "test['high_proirity'] = (test['poutcome']==1) & (test['campaign']>1)\n",
    "# train['high_proirity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['debt'] = (train['housing']+train['loan']+train['default'])>0\n",
    "test['debt'] = (test['housing']+test['loan']+test['default'])>0\n",
    "# train['debt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_jobs = [ordinal_cols['job'][j] for j in ['management','admin.','technician','services','retired']]\n",
    "    \n",
    "train['stable_job']   = train['job'].isin(stable_jobs)\n",
    "test['stable_job']   = test['job'].isin(stable_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y                    1.000000\n",
       "nr_employed          0.352288\n",
       "call                 0.321037\n",
       "prev_success         0.314060\n",
       "euribor3m            0.306278\n",
       "emp_var_rate         0.297902\n",
       "previous             0.225221\n",
       "high_proirity        0.202972\n",
       "age_group            0.166111\n",
       "contact_telephone    0.143488\n",
       "cons_price_idx       0.136839\n",
       "poutcome             0.129384\n",
       "call_frequency       0.089464\n",
       "campaign             0.066986\n",
       "marital_single       0.053561\n",
       "cons_conf_idx        0.053501\n",
       "education            0.049281\n",
       "marital_married      0.041911\n",
       "stable_job           0.041891\n",
       "month                0.035767\n",
       "job                  0.029475\n",
       "housing              0.011656\n",
       "debt                 0.009939\n",
       "loan                 0.008212\n",
       "day_of_week          0.006814\n",
       "default              0.003201\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(train.corr()['y']).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# stds = StandardScaler()\n",
    "# for col in test.columns:\n",
    "#     train[col] = stds.fit_transform(train[[col]])\n",
    "#     test[col] = stds.transform(test[[col]])\n",
    "# train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "for col in test.columns:\n",
    "    train[col] = mms.fit_transform(train[[col]])\n",
    "    test[col] = mms.transform(test[[col]])\n",
    "# train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.abs(train.corr()['y'])['job']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = np.abs(train.corr()['y'])\n",
    "# for col in test.columns:\n",
    "#     train[col] = train[col]*temp[col]\n",
    "#     test[col] = test[col]*temp[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train.drop('y',axis=1)\n",
    "y = train['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y, test_size=.2,shuffle=True)\n",
    "\n",
    "# print(y_train.value_counts())\n",
    "sampler = SMOTE()\n",
    "x_train,y_train = sampler.fit_resample(x_train,y_train)\n",
    "# print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# model = RandomForestClassifier()\n",
    "# params = {\n",
    "#     'max_depth': [2,4, 6, 8, 10],\n",
    "#     'n_estimators': [200,300],\n",
    "#     'min_samples_leaf':[1,2,3,5],\n",
    "# }\n",
    "# grid_search = RandomizedSearchCV(model, param_distributions =params,cv=5 ,verbose=3,n_iter=20,n_jobs=-1 ,scoring='f1_macro')\n",
    "# grid_search.fit(x_train, y_train)\n",
    "# # print(grid_search.best_params_)\n",
    "# print(grid_search.best_score_)\n",
    "# model = grid_search.best_estimator_\n",
    "# y_pred = model.predict(x_test)\n",
    "# grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.520065970313359"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=1000, max_depth=10,n_jobs=-1,criterion = 'entropy')\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7264792915599387"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate model\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test,y_pred,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.520065970313359"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_validate, KFold\n",
    "# k_fold = KFold(5)\n",
    "# cross_validate(model, x_train, y_train, cv = k_fold, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "\n",
    "# cm = confusion_matrix(y_test,y_pred)     #TO_DO\n",
    "\n",
    "\n",
    "# sns.heatmap(cm , annot=True ,fmt='d')\n",
    "# plt.xlabel(\"preficted Labels\")\n",
    "# plt.ylabel(\"True Lables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y.value_counts())\n",
    "# sampler = SMOTE()\n",
    "# x,y = sampler.fit_resample(x,y)\n",
    "# print(y.value_counts())\n",
    "# # model = RandomForestClassifier(max_depth=8,n_estimators=300,n_jobs=-1)\n",
    "# model.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4119, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "prediction\n",
       "0             3575\n",
       "1              544\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO-DO\n",
    "submission = pd.DataFrame({'prediction':model.predict(test)})\n",
    "print(submission.shape)\n",
    "submission.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Paths:\n",
      "['model', 'submission.csv', 'The_Marketing_Gamble.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import joblib\n",
    "\n",
    "def compress(file_names):\n",
    "    print(\"File Paths:\")\n",
    "    print(file_names)\n",
    "    compression = zipfile.ZIP_DEFLATED\n",
    "    with zipfile.ZipFile(\"result.zip\", mode=\"w\") as zf:\n",
    "        for file_name in file_names:\n",
    "            zf.write('./' + file_name, file_name, compress_type=compression)\n",
    "\n",
    "\n",
    "joblib.dump(model, 'model')\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "file_names = ['model', 'submission.csv', 'The_Marketing_Gamble.ipynb']\n",
    "compress(file_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
